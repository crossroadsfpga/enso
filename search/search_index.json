{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Ens\u014d","text":"<p>Ens\u014d is a high-performance streaming interface for NIC-application communication.</p> <p>Ens\u014d's design encompasses both hardware and software. The hardware component targets an FPGA NIC1 and implements the Ens\u014d interface. The software component uses this interface and exposes simple communication primitives called Ens\u014d Pipes. Applications can use Ens\u014d Pipes to send and receive data in different formats, such as raw packets, application-level messages, or TCP-like byte streams.</p> <p>Refer to the OSDI '23 paper for details about the design.</p>"},{"location":"#why-enso","title":"Why Ens\u014d?","text":"<p>Traditionally, NICs expose a packetized interface that software (applications or the kernel) must use to communicate with the NIC. Ens\u014d provides two main advantages over this interface:</p> <ul> <li>Flexibility: While NICs were traditionally in charge of delivering raw packets to software, an increasing amount of high-level functionality is now performed on the NIC. The packetized interface, however, forces data to be fragmented into packets that are then scattered across memory. This prevents the NIC and the application from communicating efficiently using higher-level abstractions such as application-level messages or TCP streams. Ens\u014d instead allows the NIC and the application to communicate using a contiguous stream of bytes, which can be used to represent arbitrary data.</li> <li>Performance: By forcing hardware and software to synchronize buffers for every packet, the packetized interface imposes significant per-packet overhead both in terms of CPU cycles as well as PCIe bandwidth. This results in significant performance degradation, in particular when using small requests. Ens\u014d's use of a byte stream interface allows the NIC and the application to exchange multiple packets (or messages) at once, which reduces the number of CPU cycles and PCIe transactions required to communicate each request. Moreover, by placing packets (or messages) contiguously in memory, Ens\u014d makes better use of the CPU prefetcher, vastly reducing the number of cache misses.</li> </ul>"},{"location":"#getting-started","title":"Getting started","text":"<ul> <li>Setup</li> <li>Understanding the primitives: RX Ens\u014d Pipe, TX Ens\u014d Pipe, RX/TX Ens\u014d Pipe</li> <li>Examples: Echo Server, Packet Capture, Ens\u014dGen Packet Generator</li> <li>API References: Software, Hardware</li> </ul> <ol> <li> <p>Network Interface Cards (NICs) are the hardware devices that connect a computer to the network. They are responsible for transmitting data from the CPU to the network and vice versa. FPGAs are reconfigurable hardware devices. They can be reconfigured to implement arbitrary hardware designs. Here we use an FPGA to implement a NIC with the Ens\u014d interface but the same interface could also be implemented in a traditional fixed-function hardware.\u00a0\u21a9</p> </li> </ol>"},{"location":"compiling_hardware/","title":"Compiling Hardware","text":"<p>Here we describe how to compile the hardware to produce a bitstream. This bitstream implements the Ens\u014d NIC and can be loaded into the FPGA.</p> <p>The following steps assume that you have already installed Quartus.</p> <p>Warning</p> <p>Synthesizing the hardware can take hours. If you do not need to make hardware changes, you should skip this part and automatically download the appropriate bitstream by running: <pre><code>cd &lt;root of enso repository&gt;\n./scripts/update_bitstream.sh --download\n</code></pre></p>"},{"location":"compiling_hardware/#generate-ip-cores","title":"Generate IP cores","text":"<p>Before synthesizing the bitstream for the first time, you need to generate the IP cores that are used by the hardware. To do so, run the following commands:</p> <pre><code>cd &lt;root of enso repository&gt;\n./scripts/generate_ips.sh\n</code></pre>"},{"location":"compiling_hardware/#synthesize-the-hardware","title":"Synthesize the hardware","text":"<p>After generating the IP cores, you can now synthesize the hardware by running:</p> <pre><code>cd &lt;root of enso repository&gt;\n./synthesize.sh\n</code></pre> <p>The resulting bitstream will be placed in the directory where you ran the command and it will be named <code>enso_0.sof</code>. If the design does not meet timing, the bitstream will be saved as <code>neg_slack_enso_0.sof</code>.</p> <p>Note</p> <p>The above command will use a single seed to synthesize the hardware. It is often advantageous to synthesize with multiple seeds to increase the probability of finding a design that meets timing. If you have enough memory, you can synthesize with multiple seeds in parallel. (Requires GNU Parallel to be installed.)</p> <p>To do so, you can specify multiple seeds when running the command. For example, to synthesize with seeds 1, 2, 3, and 4, run:</p> <pre><code>cd &lt;root of enso repository&gt;\n./synthesize.sh 1 2 3 4\n</code></pre> <p>This will run a separate synthesis for each seed and save the resulting bitstreams as <code>enso_{seed}.sof</code>, e.g., <code>enso_1.sof</code>, <code>enso_2.sof</code>.</p>"},{"location":"compiling_software/","title":"Compiling Software","text":"<p>Start by cloning the enso repository, if you haven't already: <pre><code>git clone https://github.com/crossroadsfpga/enso\n</code></pre></p> <p>Prepare the compilation using <code>meson</code> and compile it with <code>ninja</code>.</p> <p>Setup build directory: <pre><code>meson setup build\n</code></pre></p> <p>Now compile: <pre><code>cd build\nninja\n</code></pre></p>"},{"location":"compiling_software/#compilation-options","title":"Compilation options","text":"<p>There are a few compile-time options that you may set. You can see all the available options with: <pre><code>meson configure\n</code></pre></p> <p>If you run the above in the build directory, it also shows the current value for each option.</p> <p>To change one of the options run: <pre><code>meson configure -D&lt;option_name&gt;=&lt;value&gt;\n</code></pre></p> <p>For instance, to disable latency optimization: <pre><code>meson configure -Dlatency_opt=false\n</code></pre></p>"},{"location":"compiling_software/#build-an-application-with-enso","title":"Build an application with Ens\u014d","text":"<p>If you want to build an application that uses Ens\u014d, you should install the Ens\u014d library in your system. You can use <code>ninja</code> for that: <pre><code>cd build\nninja\nsudo ninja install\n</code></pre></p> <p>Tip</p> <p>If <code>sudo ninja install</code> fails, you may try using the following command instead: <pre><code>sudo $(which ninja) install\n</code></pre></p> <p>This will use the user <code>ninja</code> instead of the system <code>ninja</code>.</p> <p>Then, you should link the application with the Ens\u014d library. The way you do it depends on how you are compiling your code. Here are some examples using <code>gcc</code>, <code>meson</code> and <code>cmake</code>.</p> GCC with no build systemMesonCMake <pre><code>g++ -o my_app my_app.cpp -lenso\n</code></pre> <p>You may also use <code>pkg-config</code> to retrieve the flags:</p> <pre><code>g++ -o my_app my_app.cpp $(pkg-config --cflags --libs enso)\n</code></pre> <p>Add the following to your <code>meson.build</code> file: <pre><code>enso_dep = dependency('enso')\n</code></pre></p> <p>Then, you can link your application with the Ens\u014d library: <pre><code>executable('my_app', 'my_app.cpp', dependencies: [enso_dep])\n</code></pre></p> <p>Add the following to your <code>CMakeLists.txt</code> file: <pre><code>link_libraries(enso)\n</code></pre></p>"},{"location":"compiling_software/#build-the-documentation","title":"Build the documentation optional","text":"<p>You can access Ens\u014d's documentation at https://enso.cs.cmu.edu/. But if you would like to contribute to the documentation, you may choose to also build it locally.</p> <p>Install the requirements:</p> <pre><code>sudo apt update\nsudo apt install doxygen python3-pip npm\npython3 -m pip install -r docs/requirements.txt\nsudo npm install -g teroshdl\n</code></pre> <p>To build the documentation, run (from the build directory):</p> <pre><code>meson compile docs\n</code></pre> <p>While writing documentation, you can use the following command to automatically rebuild the documentation when you make changes:</p> <pre><code>cd &lt;root of enso repository&gt;\nmkdocs serve\n</code></pre> <p>Note that this does not automatically rebuild the hardware and software API reference. You need to rerun <code>meson compile docs</code> to do that.</p>"},{"location":"enso_cli/","title":"Ens\u014d CLI Tool","text":"<p>To be able to run an application using Ens\u014d, you need to first load the hardware design to the FPGA and configure it accordingly. Ens\u014d provides a CLI tool that makes this process easier. Here we describe how to install it.</p>"},{"location":"enso_cli/#installing-the-enso-cli-tool","title":"Installing the Ens\u014d CLI Tool","text":"<p>If you haven't already, clone the enso repository to the machine you want to install the tool on: <pre><code>git clone https://github.com/crossroadsfpga/enso\n</code></pre></p> <p>To install the Ens\u014d CLI Tool run: <pre><code>cd &lt;root of enso repository&gt;\npython3 -m pip install -e frontend  # Make sure this python is version &gt;=3.9.\n</code></pre></p> <p>This will install the <code>enso</code> command. In Running, we will describe how to use this command to load the hardware design and configure the NIC but you can also use the command itself to obtain usage information: <pre><code>enso --help\n</code></pre></p> <p>If, after installing the tool, you still get an error saying that the <code>enso</code> command is not found, you may need to add the <code>bin</code> directory of the python installation to your <code>PATH</code>. Refer to this stackoverflow answer for more information on how to do this.</p>"},{"location":"enso_cli/#running-the-enso-cli-tool-in-a-different-machine","title":"Running the Ens\u014d CLI Tool in a different machine optional","text":"<p>You do not need to run the <code>enso</code> command in the same machine as the one you will run an Ens\u014d-based application. You may also choose to run it from your laptop, for example. This machine can even have a different operating system, e.g., macOS.</p> <p>We refer to the machine that you plan to run the <code>enso</code> command as client and to the machine you will run the Ens\u014d-based application (the one with the FPGA) as server.</p> <p>The <code>enso</code> command provides the <code>--host &lt;host name&gt;</code> option that lets you specify a different server machine. But there are a few extra configuration steps that you need in order to use this option. First, you need to make sure that you have ssh access using a password-less key (e.g., using ssh-copy-id) from the client to the server machine. The client should also have an <code>~/.ssh/config</code> configuration file set with configuration to access the server machine. The command does not support SSH Agent so you must make sure that you specify the <code>IdentityFile</code> in the configuration file.</p> <p>If you don't yet have an <code>~/.ssh/config</code> file, you can create one and add the following lines, replacing everything between <code>&lt;&gt;</code> with the correct values: <pre><code>Host &lt;server_machine_name&gt;\n  HostName &lt;server_machine_address&gt;\n  IdentityFile &lt;private_key_path&gt;\n  User &lt;user_name&gt;\n</code></pre></p> <p><code>server_machine_name</code> is a nickname to the server machine. This is the name you specify when running the <code>enso</code> command with the <code>--host</code> option.</p>"},{"location":"enso_cli/#enable-autocompletion","title":"Enable autocompletion optional","text":"<p>Follow these instructions to enable autocompletion to the <code>enso</code> command depending on the shell that you use.</p> BashZshFish <p>Run this: <pre><code>_ENSO_COMPLETE=bash_source enso &gt; ~/.enso-complete.bash\n</code></pre></p> <p>Then add the following to your <code>.bashrc</code>: <pre><code>. ~/.enso-complete.bash\n</code></pre></p> <p>Run this: <pre><code>_ENSO_COMPLETE=zsh_source enso &gt; ~/.enso-complete.zsh\n</code></pre></p> <p>Then add the following to your <code>.zshrc</code>: <pre><code>. ~/.enso-complete.zsh\n</code></pre></p> <p>Save the following script to <code>~/.config/fish/completions/enso.fish</code>: <pre><code>_ENSO_COMPLETE=fish_source enso &gt; ~/.config/fish/completions/enso.fish\n</code></pre></p>"},{"location":"ensogen/","title":"Ens\u014dGen Packet Generator","text":"<p>Ens\u014dGen is a software packet generator built on top of the Ens\u014d NIC interface. It can send packets from a pcap and receive them back at 100Gbps line rate using a single CPU core. Ens\u014dGen is included with Ens\u014d as one of its example applications.</p>"},{"location":"ensogen/#running","title":"Running","text":"<p>Ens\u014dGen is built as part of Ens\u014d. Make sure to follow the instructions in Compiling Software to build Ens\u014d and that you have the <code>enso</code> command installed.</p> <p>You should use the <code>scripts/ensogen.sh</code> script to run Ens\u014dGen:</p> <pre><code>cd &lt;path to enso repo&gt;\n./scripts/ensogen.sh &lt;path to pcap file&gt; &lt;rate in Gbps&gt; --pcie-addr &lt;pcie address&gt; --count &lt;number of packets&gt;\n</code></pre> <p>Both <code>&lt;pcie address&gt;</code> and <code>&lt;number of packets&gt;</code> are optional but it's recommended to specify <code>&lt;pcie address&gt;</code> if you have more than one NIC in your system. If <code>&lt;number of packets&gt;</code> is not specified, Ens\u014dGen will send packets indefinitely until you stop it with Ctrl+C.</p> <p>Recall that you may obtain the PCIe address of all Ens\u014d NICs in your system by running <code>scripts/list_enso_nics.sh</code>.</p> <p>The <code>scripts/ensogen.sh</code> script makes it easier to run Ens\u014dGen by automatically figuring out the hardware rate limiter parameters based on the input pcap file and the desired rate.</p> <p>You may also choose to run Ens\u014dGen manually. Run the following command to see the available options:</p> <pre><code>cd &lt;path to enso repo&gt;\nsudo ./build/software/examples/ensogen --help\n</code></pre> <p>All these options are also available through the <code>scripts/ensogen.sh</code> script.</p>"},{"location":"ensogen/#other-features","title":"Other features","text":"<ul> <li>Save: You can save the statistics Ens\u014dGen collects to a file by using the <code>--save SAVE_FILE</code> option. This will save the statistics in a csv file called <code>SAVE_FILE</code>.</li> <li>RTT: You can also use Ens\u014dGen to measure RTT. It uses hardware timestamping and can keep track of RTTs with 5ns precision. To enable RTT measurement, run Ens\u014dGen with the <code>--rtt</code> flag.</li> <li>RTT Histogram: The <code>--rtt</code> option will report the average RTT among all packets. You can also enable RTT histogram to record the RTT of every packet. This allows you to generate RTT CDFs as well as calculate relevant metrics such as 99th percentile latency. To enable RTT histogram, run Ens\u014dGen with the <code>--rtt-hist HIST_FILE</code>. This will save the RTT histogram in a file called <code>HIST_FILE</code>.</li> </ul>"},{"location":"getting_started/","title":"Getting Started","text":"<p>To use Ens\u014d, you first need to make sure that your system meets the requirements in terms of hardware and software.</p>"},{"location":"getting_started/#system-requirements","title":"System requirements","text":"<p>Ens\u014d currently requires an Intel Stratix 10 MX FPGA. Support for other boards might be added in the future. Ens\u014d's codebase also assumes an x86-64 architecture and that the system is running Linux. Ens\u014d was extensively tested on Ubuntu 22.04 and 16.04, but it should work on other Linux distributions as well.</p> <p>In what follows, we describe how to setup the software and install the required dependencies.</p>"},{"location":"getting_started/#dependencies","title":"Dependencies","text":"<p>Ens\u014d has the following dependencies:</p> <ul> <li>GCC (&gt;= 9.0)</li> <li>Python (&gt;= 3.9)</li> <li>pip</li> <li>Meson (&gt;= 0.58)</li> <li>Ninja</li> <li>libpcap</li> <li>wget</li> </ul> <p>There are also python dependencies listed in <code>requirements.txt</code> that can be installed with <code>pip</code>.</p> <p>If you are using Ubuntu 22.04 or other recent Debian-based distribution, you may be able to use the <code>setup.sh</code> script to install all the dependencies. The script is located at the root of the Ens\u014d repository. To run it, simply execute:</p> <pre><code>./setup.sh\n</code></pre> <p>In Ubuntu 22.04 or other recent Debian-based distributions these dependencies can also be manually installed with the following commands: <pre><code>sudo apt update\nsudo apt install \\\npython3.9 \\\npython3-pip \\\npython3-setuptools \\\npython3-wheel \\\ngcc \\\ng++ \\\nlibpcap-dev \\\ntshark\n\nsudo python3 -m pip install meson ninja  # Installing system-wide.\npython3 -m pip install -r requirements.txt\n</code></pre></p>"},{"location":"getting_started/#huge-pages","title":"Huge pages","text":"<p>Ens\u014d requires 2MB huge pages to be allocated in the system. You may use the following snippet adapted from ixy to allocate them. In this example, we allocate 2,048 2MB huge pages per NUMA node.</p> <pre><code>mkdir -p /mnt/huge\n(mount | grep /mnt/huge) &gt; /dev/null || mount -t hugetlbfs hugetlbfs /mnt/huge\nfor i in /sys/devices/system/node/node[0-9]*\ndo\necho 2048 &gt; \"$i\"/hugepages/hugepages-2048kB/nr_hugepages\ndone\n</code></pre>"},{"location":"getting_started/#quartus","title":"Quartus","text":"<p>To be able to load or synthesize the hardware, you also need to install Intel Quartus 19.3 as well as the Stratix 10 device support (same link).</p> <p>You should also make sure that <code>quartus</code> and its tools are in your <code>PATH</code>. You may do so by adding the following lines to your <code>~/.bashrc</code> file:</p> <pre><code># Make sure this points to the Quartus installation directory.\nexport quartus_dir=\n\nexport INTELFPGAOCLSDKROOT=\"$quartus_dir/19.3/hld\"\nexport QUARTUS_ROOTDIR=\"$quartus_dir/19.3/quartus\"\nexport QSYS_ROOTDIR=\"$quartus_dir/19.3/qsys/bin\"\nexport IP_ROOTDIR=\"$quartus_dir/19.3/ip/\"\nexport PATH=$quartus_dir/19.3/quartus/bin:$PATH\nexport PATH=$quartus_dir/19.3/modelsim_ase/linuxaloem:$PATH\nexport PATH=$quartus_dir/19.3/quartus/sopc_builder/bin:$PATH\n</code></pre> <p>Note</p> <p>Some distributions (e.g., Ubuntu) include code in the <code>.bashrc</code> file to prevent it from running in non-interactive environments. This might prevent the above lines from running in some settings. You should remove or comment out the following lines in the <code>.bashrc</code> file:</p> <pre><code># If not running interactively, don't do anything\ncase $- in\n*i*) ;;\n*) return;;\nesac\n</code></pre>"},{"location":"running/","title":"Running","text":"<p>Running an application with Ens\u014d requires first loading the bitstream to the FPGA and configuring the NIC. This can be done using the Ens\u014d CLI tool.</p>"},{"location":"running/#installing-the-bitstream","title":"Installing the bitstream","text":"<p>The hardware design is defined using a bitstream. You can automatically download the appropriate bitstream or follow the steps in Compiling Hardware to produce your own (it may take a few hours).</p> <p>To automatically download and install the appropriate bitstream, run: <pre><code>cd &lt;root of enso repository&gt;\n./scripts/update_bitstream.sh --download\n</code></pre></p> <p>If you want to specify a different bitstream, you can install it by running: <pre><code>cd &lt;root of enso repository&gt;\n./scripts/update_bitstream.sh &lt;bitstream path&gt;\n</code></pre></p> <p>You only need to install the bitstream once or if you want to use a different one.</p>"},{"location":"running/#loading-the-bitstream-and-configuring-the-nic","title":"Loading the bitstream and configuring the NIC","text":"<p>Before running any software you need to make sure that the FPGA is loaded with the bitstream that you installed.</p> <p>Use the <code>enso</code> command to load the bitstream and automatically configure the NIC with the default values. <pre><code>enso &lt;path to enso repository&gt; --fpga &lt;FPGA ID&gt;\n</code></pre></p> <p>You should use the <code>--fpga</code> flag to specify the ID of the FPGA that you want to load. You may use the <code>scripts/list_enso_nics.sh</code> script to list the IDs of all compatible FPGAs in your system.</p> <p>You may also specify other options to configure the NIC. Refer to <code>enso --help</code> for more information.</p> <p>After the FPGA has been loaded and configured, the <code>enso</code> command will open the JTAG console. You may use the JTAG console to send extra configuration to the NIC and to retrieve NIC statistics. You can type <code>help</code> to get a list of available commands.</p> <p>Once you are done using the JTAG console, you can press Ctrl+C to quit. You can continue to use the NIC even after the JTAG console has been closed.</p> <p>The first time you load the NIC, Linux will not recognize it as a PCIe device until you reboot the system. You can use the <code>scripts/list_enso_nics.sh</code> script to show all the available Ens\u014d NICs in your system. If the NIC does not show up as a PCIe device after you load the bitstream, reboot the system.</p>"},{"location":"running/#running-an-application","title":"Running an application","text":"<p>Once the NIC has been loaded and you can see the device listed when you run <code>scripts/list_enso_nics.sh</code>, you are ready to run an application. Ens\u014d comes with some example applications which are built together with Ens\u014d. You may run any of these without specifying command line arguments to obtain usage information. For example, to obtain instructions on how to run an echo server do: <pre><code>cd &lt;root of enso repository&gt;\n./build/software/examples/echo\n</code></pre></p> <p>This will print the usage information: <pre><code>Usage: ./build/software/examples/echo NB_CORES NB_QUEUES NB_CYCLES\n\nNB_CORES: Number of cores to use.\nNB_QUEUES: Number of queues per core.\nNB_CYCLES: Number of cycles to busy loop when processing each packet.\n</code></pre></p> <p>In Ens\u014d, it is recommended to use at least two queues per core for maximum performance. For instance, this application could be run with: <pre><code>./build/software/examples/echo 1 2 0\n</code></pre></p> <p>This will use one CPU core, 2 queues and will not busy loop when processing each packet.</p> <p>Note</p> <p>You can also refer to Build an application with Ens\u014d for instructions on how to build your own application.</p>"},{"location":"software_api/","title":"Software API Reference","text":"<p>This page contains the API reference for the software component of Ens\u014d.</p> <p>Main components:</p> <ul> <li>Per-thread device class</li> <li>Ens\u014d Pipe classes: RX Ens\u014d Pipe, TX Ens\u014d Pipe, RX/TX Ens\u014d Pipe</li> <li>Low-Level hardware configuration functions</li> </ul> <p>Or check all the source files.</p>"},{"location":"examples/echo/","title":"Raw packet echo server","text":""},{"location":"hardware/","title":"Hardware Reference","text":""},{"location":"hardware/counters/","title":"Hardware Counters","text":"Counter Description <code>IN_PKT</code> Number of packets that arrived at the Ethernet port. <code>OUT_PKT</code> Number of packets that left the Ethernet port. <code>OUT_IN_COMP_PKT</code> Number of packets that left the <code>input_comp</code> module. <code>OUT_PARSER_PKT</code> Number of packets that left the Parser module. <code>MAX_PARSER_FIFO</code> Maximum occupancy of the FIFO that holds packets coming from the <code>parser</code> module. <code>FD_IN_PKT</code> Number of packets that entered the Flow Director module. <code>FD_OUT_PKT</code> Number of packets that left the Flow Director module. <code>MAX_FD_OUT_FIFO</code> Maximum occupancy of the FIFO that holds packets coming from the Flow Director module. <code>IN_DATAMOVER_PKT</code> Number of packets that entered the Data Mover module. <code>IN_EMPTYLIST_PKT</code> Number of entries enqueued in the empty list. <code>OUT_EMPTYLIST_PKT</code> Number of entries dequeued from the empty list. <code>PKT_ETH</code> Number of packets forwarded back to the Ethernet without going to the host. <code>PKT_DROP</code> Number of packets dropped. <code>PKT_PCIE</code> Number of packets forwarded to the host over PCIe. <code>MAX_DM2PCIE_FIFO</code> Maximum occupancy of the packet FIFO connecting the data mover to <code>pdu_gen</code>. <code>MAX_DM2PCIE_META_FIFO</code> Maximum occupancy of the metadata FIFO connecting the data mover to <code>pdu_gen</code>. <code>PCIE_PKT</code> Number of packets sent to PCIe that entered the <code>pdu_gen</code> module. <code>PCIE_META</code> Number of metadata entries for packets sent to PCIe that entered the <code>pdu_gen</code> module. <code>DM_PCIE_PKT</code> Number of packets that entered the packet FIFO connecting the data mover to the <code>pdu_gen</code> module. <code>DM_PCIE_META</code> Number of metadata entries that entered the metadata FIFO connecting the data mover to the <code>pdu_gen</code> module. <code>DM_ETH_PKT</code> Number of TX packets directed to Ethernet. <code>RX_DMA_PKT</code> Number of packets sent to the DMA engine (RX path). <code>RX_PKT_HEAD_UPD</code> Number of updates to the RX packet queue head pointer from software. <code>TX_DSC_TAIL_UPD</code> Number of updates to the TX descriptor queue tail pointer from software. <code>DMA_REQUEST</code> Number of actual DMA requests  sent to PCIe, a single packet may require multiple DMA requests as each flit requires a separate DMA requests and some packets also need a descriptor. <code>RULE_SET</code> Number of rules set in the Flow Table. <code>EVICTION</code> Number of evictions in the Flow Table. Evictions are currently not implemented so this counter effectively reports the number of ignored evictions. <code>MAX_PDUGEN_PKT_FIFO</code> Maximum occupancy of the packet FIFO in the <code>pdu_gen</code> module. If either this FIFO or <code>MAX_PDUGEN_META_FIFO</code> are at their maximum capacity, this indicates that the DMA engine is not able to consume packets fast enough. <code>MAX_PDUGEN_META_FIFO</code> Maximum occupancy of the metadata FIFO in the <code>pdu_gen</code> module. If either this FIFO or <code>MAX_PDUGEN_PKT_FIFO</code> are at their maximum capacity, this indicates that the DMA engine is not able to consume packets fast enough. <code>PCIE_CORE_FULL</code> Number of cycles that a packet could not be sent to memory due to backpressure from PCIe. <code>RX_DMA_DSC_CNT</code> Number of RX descriptors that were DMAed to host memory. <code>RX_DMA_DSC_DROP_CNT</code> Number of RX descriptors that were dropped. This does not indicate a problem, it happens when hardware determines that software already knows the latest pointer for a given packet queue and does not need an extra descriptor. <code>RX_DMA_PKT_FLIT_CNT</code> Number of RX flits DMAed to host memory. <code>RX_DMA_PKT_FLIT_DROP_CNT</code> Number of RX flits that should have been DMAed but were dropped instead. <code>CPU_DSC_BUF_FULL</code> Number of times a packet could not be sent to memory because the corresponding descriptor buffer was full. <code>CPU_DSC_BUF_IN</code> Number of packets that entered the descriptor queue manager. This number includes packets that do not trigger descriptors as well as placeholder packets used by the reactive descriptor mechanism. <code>CPU_DSC_BUF_OUT</code> Number of packets that left the descriptor queue manager. This number includes packets that do not trigger descriptors as well as placeholder packets used by the reactive descriptor mechanism. <code>CPU_PKT_BUF_FULL</code> Number of times a packet could not be sent to memory because the corresponding packet buffer was full. <code>CPU_PKT_BUF_IN</code> Number of packets that entered the packet queue manager. This number also includes placeholder packets used by the reactive descriptor mechanism. <code>CPU_PKT_BUF_OUT</code> Number of packets that left the packet queue manager. This number also includes placeholder packets used by the reactive descriptor mechanism. <code>MAX_PCIE_PKT_FIFO</code> Maximum queue occupancy, in number of flits (64-byte chunks), ever observed in the FIFO that feeds packets to the DMA engine. This usually increases when one of the memory buffers becomes full (check the <code>CPU_DSC_BUF_FULL</code> and <code>CPU_PKT_BUF_FULL</code> to verify) or if the PCIe is back-pressuring the design (check <code>PCIE_CORE_FULL</code> to verify). Contention may also happen if the TX path is sending too many completion notifications. <code>MAX_PCIE_META_FIFO</code> Maximum queue occupancy, in number of packets, ever observed in the FIFO that feeds metadata to the DMA engine. This usually increases when one of the memory buffers becomes full (check the <code>CPU_DSC_BUF_FULL</code> and <code>CPU_PKT_BUF_FULL</code> to verify) or if the PCIe is back-pressuring the design (check <code>PCIE_CORE_FULL</code> to verify).  Contention may also happen if the TX path is sending too many completion notifications. <code>PCIE_RX_IGNORED_HEAD</code> When software updates the head pointer for an RX packet queue, the hardware needs to send a descriptor if there are packets left in the queue. But if software updates the pointer too often, the queue that holds these updates may overflow and cause some of these updates to be ignored. When this happens this counter is incremented. Note that the head pointer is always updated to the value that software set what is ignored is the extra descriptor, not the update itself. <code>PCIE_TX_Q_FULL_SIGNALS</code> When any of the queues in the <code>cpu_to_fpga</code> module becomes full and we still try to write to it, the appropriate bit on this signal is set. This must remain zero to ensure correct behavior.- bit 0: set when <code>dsc_read_queue</code> becomes full.- bit 1: set when <code>rddm_desc_queue</code> becomes full.- bit 2: set when <code>rddm_prio_queue</code> becomes full.- bit 3: set when <code>meta_queue</code> becomes full.- bit 4: set when <code>pkt_queue</code> becomes full.- bit 5: set when <code>compl_buf</code> becomes full.- bit 6: set when <code>out_pkt</code> queue becomes full.- bit 7: set when <code>out_config</code> queue becomes full. <code>PCIE_TX_DSC_CNT</code> Number of TX descriptors processed by <code>cpu_to_fpga</code>. <code>PCIE_TX_EMPTY_TAIL_CNT</code> Number of TX tail pointer updates that were ignored since there were no descriptors to be read (i.e., the head was equal to the new tail value). <code>PCIE_TX_DSC_READ_CNT</code> Number of TX descriptors read from host memory. <code>PCIE_TX_PKT_READ_CNT</code> Number of TX packet flits read from host memory. <code>PCIE_TX_BATCH_CNT</code> Number of batches that left <code>cpu_to_fpga</code>. <code>PCIE_TX_MAX_INFLIGH_DSCS</code> Maximum number of in-flight descriptor reads in the TX path. <code>PCIE_TX_MAX_NB_REQ_DSCS</code> Maximum number of descriptors requested at once in the TX path. This is determined by hardware and is independent from the TX descriptor pointer updates controlled by software. <code>PCIE_TX_DMA_PKT</code> Number of packets DMAed from CPU (TX path) that left the DMA engine. <code>PCIE_TOP_FULL_SIGNALS_1</code> When any of the packet queue manager fifos become full in the <code>pcie_top</code> module and we still try to write to it, the bit on this signal corresponding to the packet queue is set. This must remain zero to ensure correct behavior. This signal is only relevant when <code>DEBUG</code> is defined before synthesis. <code>PCIE_TOP_FULL_SIGNALS_2</code> When any of the remaining queues in the <code>pcie_top</code> module becomes full (besides the ones in <code>PCIE_TOP_FULL_SIGNALS_1</code>) and we still try to write to it, the appropriate bit on this signal is set. This must remain zero to ensure correct behavior. This signal is only relevant when <code>DEBUG</code> is defined before synthesis. - bit 0: set when <code>head_upd_queue</code> becomes full.- bit 1: set when <code>in_queue</code> becomes full.- bit 2: set when <code>dsc_q_mngr</code> becomes full.- bit 3: set when <code>fpga_to_cpu_inst</code> input packet fifo becomes full.- bit 4: set when <code>fpga_to_cpu_inst</code> input meta fifo becomes full.- bit 5: set when <code>fpga_to_cpu_inst</code> input completion fifo becomes full."},{"location":"hardware/modules/basic_data_mover/","title":"Entity: basic_data_mover","text":"<ul> <li>File: basic_data_mover.sv</li> </ul>"},{"location":"hardware/modules/basic_data_mover/#diagram","title":"Diagram","text":""},{"location":"hardware/modules/basic_data_mover/#ports","title":"Ports","text":"Port name Direction Type Description clk input rst input meta_valid input metadata_t input meta_ready output pkt_buffer_address output [PKTBUF_AWIDTH-1:0] pkt_buffer_read output pkt_buffer_readvalid input pkt_buffer_readdata input emptylist_in_data output [PKT_AWIDTH-1:0] emptylist_in_valid output emptylist_in_ready input disable_pcie input pcie_rx_pkt_sop output pcie_rx_pkt_eop output pcie_rx_pkt_valid output pcie_rx_pkt_data output [511:0] pcie_rx_pkt_empty output [5:0] pcie_rx_pkt_ready input pcie_rx_pkt_almost_full input pcie_rx_meta_valid output pcie_rx_meta_data output pcie_rx_meta_ready input pcie_rx_meta_almost_full input pcie_tx_pkt_sop input pcie_tx_pkt_eop input pcie_tx_pkt_valid input pcie_tx_pkt_data input [511:0] pcie_tx_pkt_empty input [5:0] pcie_tx_pkt_ready output eth_pkt_sop output eth_pkt_eop output eth_pkt_valid output eth_pkt_data output [511:0] eth_pkt_empty output [5:0] eth_pkt_ready input eth_pkt_almost_full input ## Instantiations <ul> <li>hp_flags: hyper_pipe</li> </ul>"},{"location":"hardware/modules/basic_data_mover/#state-machines","title":"State machines","text":""},{"location":"hardware/modules/configurator/","title":"Entity: configurator","text":"<ul> <li>File: configurator.sv</li> </ul>"},{"location":"hardware/modules/configurator/#diagram","title":"Diagram","text":""},{"location":"hardware/modules/configurator/#ports","title":"Ports","text":"Port name Direction Type Description clk input rst input in_config_data input in_config_valid input in_config_ready output flow_table_config_t output out_conf_ft_valid output out_conf_ft_ready input timestamp_config_t output out_conf_ts_valid output out_conf_ts_ready input rate_limit_config_t output out_conf_rl_valid output out_conf_rl_ready input fallback_queues_config_t output out_conf_fq_valid output out_conf_fq_ready input"},{"location":"hardware/modules/dc_back_pressure/","title":"Entity: dc_back_pressure","text":"<ul> <li>File: dc_back_pressure.sv</li> </ul>"},{"location":"hardware/modules/dc_back_pressure/#diagram","title":"Diagram","text":""},{"location":"hardware/modules/dc_back_pressure/#generics","title":"Generics","text":"Generic name Type Value Description FULL_LEVEL 490 ## Ports Port name Direction Type Description clk input rst input csr_address output csr_read output csr_write output csr_readdata input [31:0] csr_writedata output [31:0] almost_full output"},{"location":"hardware/modules/esram_wrapper/","title":"Entity: esram_wrapper","text":"<ul> <li>File: esram_wrapper.sv</li> </ul>"},{"location":"hardware/modules/esram_wrapper/#diagram","title":"Diagram","text":""},{"location":"hardware/modules/esram_wrapper/#ports","title":"Ports","text":"Port name Direction Type Description clk_esram_ref input esram_pll_lock output clk_esram output clk_esram output wren input wraddress input [PKTBUF_AWIDTH-1:0] wrdata input [519:0] rden input rdaddress input [PKTBUF_AWIDTH-1:0] rd_valid output rddata output [519:0] ## Instantiations <ul> <li>esrm_sim: bram_simple2port</li> <li>esram_0: esram</li> </ul>"},{"location":"hardware/modules/flow_director/","title":"Entity: flow_director","text":"<ul> <li>File: flow_director.sv</li> </ul>"},{"location":"hardware/modules/flow_director/#diagram","title":"Diagram","text":""},{"location":"hardware/modules/flow_director/#ports","title":"Ports","text":"Port name Direction Type Description clk input rst input in_meta_data input in_meta_valid input in_meta_ready output out_meta_data output out_meta_valid output out_meta_ready input fallback_queues_config_t input conf_fd_valid input conf_fd_ready output"},{"location":"hardware/modules/flow_table_wrapper/","title":"Entity: flow_table_wrapper","text":"<ul> <li>File: flow_table_wrapper.sv</li> </ul>"},{"location":"hardware/modules/flow_table_wrapper/#diagram","title":"Diagram","text":""},{"location":"hardware/modules/flow_table_wrapper/#ports","title":"Ports","text":"Port name Direction Type Description clk input rst input in_meta_data input in_meta_valid input in_meta_ready output out_meta_data output out_meta_valid output out_meta_ready input flow_table_config_t input in_control_valid input in_control_ready output out_control_done output eviction_cnt output [31:0] ## Instantiations <ul> <li>s_hash0: hash_func</li> <li>s_hash1: hash_func</li> <li>s_hash2: hash_func</li> <li>s_hash3: hash_func</li> <li>p_hash0: hash_func</li> <li>p_hash1: hash_func</li> <li>p_hash2: hash_func</li> <li>p_hash3: hash_func</li> <li>FT_0: bram_true2port</li> <li>FT_1: bram_true2port</li> <li>FT_2: bram_true2port</li> <li>FT_3: bram_true2port</li> </ul>"},{"location":"hardware/modules/flow_table_wrapper/#state-machines","title":"State machines","text":""},{"location":"hardware/modules/hash_func/","title":"Entity: hash_func","text":"<ul> <li>File: hash_func.sv</li> </ul>"},{"location":"hardware/modules/hash_func/#diagram","title":"Diagram","text":""},{"location":"hardware/modules/hash_func/#ports","title":"Ports","text":"Port name Direction Type Description clk input rst input stall input initval input [31:0] tuple_in input tuple_t tuple_in_valid input hashed_valid output hashed output [31:0]"},{"location":"hardware/modules/hyper_pipe/","title":"Entity: hyper_pipe","text":"<ul> <li>File: hyper_pipe.sv</li> </ul>"},{"location":"hardware/modules/hyper_pipe/#diagram","title":"Diagram","text":""},{"location":"hardware/modules/hyper_pipe/#description","title":"Description","text":""},{"location":"hardware/modules/hyper_pipe/#generics","title":"Generics","text":"Generic name Type Value Description WIDTH 1 NUM_PIPES 1 ## Ports Port name Direction Type Description clk input din input [WIDTH-1:0] dout output [WIDTH-1:0]"},{"location":"hardware/modules/hyper_pipe_root/","title":"Entity: hyper_pipe_root","text":"<ul> <li>File: hyper_pipe_root.sv</li> </ul>"},{"location":"hardware/modules/hyper_pipe_root/#diagram","title":"Diagram","text":""},{"location":"hardware/modules/hyper_pipe_root/#ports","title":"Ports","text":"Port name Direction Type Description clk input rst input clk_datamover input rst_datamover input in_sop input in_eop input in_data input [511:0] in_empty input [5:0] in_valid input out_data input [511:0] out_valid input out_sop input out_eop input out_empty input [5:0] out_almost_full input esram_pkt_buf_wren input esram_pkt_buf_wraddress input [PKTBUF_AWIDTH-1:0] esram_pkt_buf_wrdata input [519:0] esram_pkt_buf_rden input esram_pkt_buf_rdaddress input [PKTBUF_AWIDTH-1:0] esram_pkt_buf_rd_valid input esram_pkt_buf_rddata input [519:0] reg_in_sop output reg_in_eop output reg_in_data output [511:0] reg_in_empty output [5:0] reg_in_valid output reg_out_data output [511:0] reg_out_valid output reg_out_sop output reg_out_eop output reg_out_empty output [5:0] reg_out_almost_full output reg_esram_pkt_buf_wren output reg_esram_pkt_buf_wraddress output [PKTBUF_AWIDTH-1:0] reg_esram_pkt_buf_wrdata output [519:0] reg_esram_pkt_buf_rden output reg_esram_pkt_buf_rdaddress output [PKTBUF_AWIDTH-1:0] reg_esram_pkt_buf_rd_valid output reg_esram_pkt_buf_rddata output [519:0] ## Instantiations <ul> <li>hp_in_sop: hyper_pipe</li> <li>hp_in_eop: hyper_pipe</li> <li>hp_in_data: hyper_pipe</li> <li>hp_in_empty: hyper_pipe</li> <li>hp_in_valid: hyper_pipe_rst</li> <li>hp_out_data: hyper_pipe</li> <li>hp_out_valid: hyper_pipe_rst</li> <li>hp_out_sop: hyper_pipe</li> <li>hp_out_eop: hyper_pipe</li> <li>hp_out_empty: hyper_pipe</li> <li>hp_out_almost_full: hyper_pipe_rst</li> <li>hp_esram_pkt_buf_wren: hyper_pipe_rst</li> <li>hp_esram_pkt_buf_wraddress: hyper_pipe</li> <li>hp_esram_pkt_buf_wrdata: hyper_pipe</li> <li>hp_esram_pkt_buf_rden: hyper_pipe_rst</li> <li>hp_esram_pkt_buf_rdaddress: hyper_pipe</li> <li>hp_esram_pkt_buf_rd_valid: hyper_pipe_rst</li> <li>hp_esram_pkt_buf_rddata: hyper_pipe</li> </ul>"},{"location":"hardware/modules/hyper_pipe_rst/","title":"Entity: hyper_pipe_rst","text":"<ul> <li>File: hyper_pipe_rst.sv</li> </ul>"},{"location":"hardware/modules/hyper_pipe_rst/#diagram","title":"Diagram","text":""},{"location":"hardware/modules/hyper_pipe_rst/#description","title":"Description","text":""},{"location":"hardware/modules/hyper_pipe_rst/#generics","title":"Generics","text":"Generic name Type Value Description WIDTH 1 NUM_PIPES 1 ## Ports Port name Direction Type Description clk input rst input din input [WIDTH-1:0] dout output [WIDTH-1:0]"},{"location":"hardware/modules/input_comp/","title":"Entity: input_comp","text":"<ul> <li>File: input_comp.sv</li> </ul>"},{"location":"hardware/modules/input_comp/#diagram","title":"Diagram","text":""},{"location":"hardware/modules/input_comp/#ports","title":"Ports","text":"Port name Direction Type Description clk input rst input eth_sop input eth_eop input eth_data input [511:0] eth_empty input [5:0] eth_valid input pkt_buffer_address output [PKTBUF_AWIDTH-1:0] pkt_buffer_write output pkt_buffer_writedata output flit_t emptylist_out_data input [PKT_AWIDTH-1:0] emptylist_out_valid input emptylist_out_ready output pkt_sop output pkt_eop output pkt_valid output pkt_data output [511:0] pkt_empty output [5:0] pkt_ready input meta_valid output meta_data output metadata_t meta_ready input"},{"location":"hardware/modules/my_stats/","title":"Entity: my_stats","text":"<ul> <li>File: my_stats.sv</li> </ul>"},{"location":"hardware/modules/my_stats/#diagram","title":"Diagram","text":""},{"location":"hardware/modules/my_stats/#ports","title":"Ports","text":"Port name Direction Type Description arst input clk_tx input tx_ready input tx_valid input tx_data input [511:0] tx_sop input tx_eop input tx_empty input [5:0] clk_rx input rx_sop input rx_eop input rx_empty input [5:0] rx_data input [511:0] rx_valid input rx_ready input o_rx_sop output o_rx_eop output o_rx_empty output [5:0] o_rx_data output [511:0] o_rx_valid output clk_status input status_addr input [29:0] status_read input status_write input status_writedata input [31:0] status_readdata output [31:0] status_readdata_valid output ## Processes - unnamed: ( @(posedge clk_status) ) - Type: always - Description //////////////////////// /////////////////////// - unnamed: ( @(posedge clk_rx) ) - Type: always - Description //////////////////////// /////////////////////// - unnamed: ( @(posedge clk_tx) ) - Type: always - Description //////////////////////// ///////////////////////"},{"location":"hardware/modules/parser/","title":"Entity: parser","text":"<ul> <li>File: parser.sv</li> </ul>"},{"location":"hardware/modules/parser/#diagram","title":"Diagram","text":""},{"location":"hardware/modules/parser/#description","title":"Description","text":""},{"location":"hardware/modules/parser/#ports","title":"Ports","text":"Port name Direction Type Description clk input rst input disable_pcie input in_pkt_data input [511:0] in_pkt_valid input in_pkt_ready output in_pkt_sop input in_pkt_eop input in_pkt_empty input [5:0] out_pkt_data output [511:0] out_pkt_valid output out_pkt_ready input out_pkt_sop output out_pkt_eop output out_pkt_empty output [5:0] in_meta_data input in_meta_valid input in_meta_ready output out_meta_data output out_meta_valid output out_meta_ready input"},{"location":"hardware/modules/pdu_gen/","title":"Entity: pdu_gen","text":"<ul> <li>File: pdu_gen.sv</li> </ul>"},{"location":"hardware/modules/pdu_gen/#diagram","title":"Diagram","text":""},{"location":"hardware/modules/pdu_gen/#generics","title":"Generics","text":"Generic name Type Value Description OUT_PKT_Q_DEPTH 64 OUT_META_Q_DEPTH 128 PKT_Q_ALMOST_FULL_THRESHOLD OUT_PKT_Q_DEPTH - MAX_PKT_SIZE * 2 META_Q_ALMOST_FULL_THRESHOLD OUT_META_Q_DEPTH - 8 ## Ports Port name Direction Type Description clk input rst input in_sop input in_eop input in_data input [511:0] in_empty input [5:0] in_valid input in_ready output in_meta_valid input in_meta_data input in_meta_ready output pcie_pkt_buf_data output pcie_pkt_buf_valid output pcie_pkt_buf_ready input pcie_meta_buf_data output pcie_meta_buf_valid output pcie_meta_buf_ready input out_pkt_queue_occup output [31:0] out_meta_queue_occup output [31:0]"},{"location":"hardware/modules/rate_limiter/","title":"Entity: rate_limiter","text":"<ul> <li>File: rate_limiter.sv</li> </ul>"},{"location":"hardware/modules/rate_limiter/#diagram","title":"Diagram","text":""},{"location":"hardware/modules/rate_limiter/#description","title":"Description","text":""},{"location":"hardware/modules/rate_limiter/#ports","title":"Ports","text":"Port name Direction Type Description clk input rst input in_pkt_data input [511:0] in_pkt_valid input in_pkt_ready output in_pkt_sop input in_pkt_eop input in_pkt_empty input [5:0] out_pkt_data output [511:0] out_pkt_valid output out_pkt_ready input out_pkt_sop output out_pkt_eop output out_pkt_empty output [5:0] rate_limit_config_t input conf_rl_valid input conf_rl_ready output"},{"location":"hardware/modules/timestamp/","title":"Entity: timestamp","text":"<ul> <li>File: timestamp.sv</li> </ul>"},{"location":"hardware/modules/timestamp/#diagram","title":"Diagram","text":""},{"location":"hardware/modules/timestamp/#description","title":"Description","text":"<p>Timestamp outgoing packets and calculate RTT for incoming packets using this  timestamp. For incoming packets we also replace the timestamp with the RTT  (in number of cycles). Must be explicitly enabled using the configuration  interface. Otherwise this module does nothing.</p>"},{"location":"hardware/modules/timestamp/#generics","title":"Generics","text":"Generic name Type Value Description TIMESTAMP_WIDTH 32 TIMESTAMP_OFFSET (112+32) ## Ports Port name Direction Type Description clk input rst input rx_in_pkt_data input [511:0] RX input. rx_in_pkt_valid input rx_in_pkt_ready output rx_in_pkt_sop input rx_in_pkt_eop input rx_in_pkt_empty input [5:0] rx_out_pkt_data output [511:0] RX output. rx_out_pkt_valid output rx_out_pkt_ready input rx_out_pkt_sop output rx_out_pkt_eop output rx_out_pkt_empty output [5:0] tx_in_pkt_data input [511:0] TX input. tx_in_pkt_valid input tx_in_pkt_ready output tx_in_pkt_sop input tx_in_pkt_eop input tx_in_pkt_empty input [5:0] tx_out_pkt_data output [511:0] TX output. tx_out_pkt_valid output tx_out_pkt_ready input tx_out_pkt_sop output tx_out_pkt_eop output tx_out_pkt_empty output [5:0] timestamp_config_t input Configuration. conf_ts_valid input conf_ts_ready output"},{"location":"hardware/modules/top/","title":"Entity: top","text":"<ul> <li>File: top.sv</li> </ul>"},{"location":"hardware/modules/top/#diagram","title":"Diagram","text":""},{"location":"hardware/modules/top/#ports","title":"Ports","text":"Port name Direction Type Description clk input rst input clk_datamover input rst_datamover input clk_pcie input rst_pcie input in_sop input in_eop input in_data input [511:0] in_empty input [5:0] in_valid input out_data output [511:0] out_valid output out_sop output out_eop output out_empty output [5:0] out_almost_full input eth_port_nb output pcie_wrdm_desc_ready input pcie_wrdm_desc_valid output pcie_wrdm_desc_data output [173:0] pcie_wrdm_prio_ready input pcie_wrdm_prio_valid output pcie_wrdm_prio_data output [173:0] pcie_wrdm_tx_valid input pcie_wrdm_tx_data input [31:0] pcie_rddm_desc_ready input pcie_rddm_desc_valid output pcie_rddm_desc_data output [173:0] pcie_rddm_prio_ready input pcie_rddm_prio_valid output pcie_rddm_prio_data output [173:0] pcie_rddm_tx_valid input pcie_rddm_tx_data input [31:0] pcie_bas_waitrequest input pcie_bas_address output [63:0] pcie_bas_byteenable output [63:0] pcie_bas_read output pcie_bas_readdata input [511:0] pcie_bas_readdatavalid input pcie_bas_write output pcie_bas_writedata output [511:0] pcie_bas_burstcount output [3:0] pcie_bas_response input [1:0] pcie_address_0 input [PCIE_ADDR_WIDTH-1:0] pcie_write_0 input pcie_read_0 input pcie_readdatavalid_0 output pcie_readdata_0 output [511:0] pcie_writedata_0 input [511:0] pcie_byteenable_0 input [63:0] pcie_rddm_address input [63:0] pcie_rddm_write input pcie_rddm_writedata input [511:0] pcie_rddm_byteenable input [63:0] pcie_rddm_waitrequest output reg_esram_pkt_buf_wren output reg_esram_pkt_buf_wraddress output [PKTBUF_AWIDTH-1:0] reg_esram_pkt_buf_wrdata output [519:0] reg_esram_pkt_buf_rden output reg_esram_pkt_buf_rdaddress output [PKTBUF_AWIDTH-1:0] esram_pkt_buf_rd_valid input esram_pkt_buf_rddata input [519:0] clk_status input status_addr input [29:0] status_read input status_write input status_writedata input [31:0] status_readdata output [31:0] status_readdata_valid output ## Signals Name Type Description sw_reset_r1 logic //////////////////////// /////////////////////// ## Instantiations <ul> <li>rate_limiter_inst: rate_limiter</li> <li>out_eth_store_forward_fifo: fifo_pkt_wrapper</li> <li>timestamp_inst: timestamp</li> <li>reg_io_inst: hyper_pipe_root</li> <li>input_comp_0: input_comp</li> <li>parser_0: parser</li> <li>parser_out_fifo: dc_fifo_wrapper_infill</li> <li>configurator_inst: configurator</li> <li>flow_table_wrapper_0: flow_table_wrapper</li> <li>flow_director_inst: flow_director</li> <li>flow_director_out_fifo: dc_fifo_wrapper_infill</li> <li>data_mover_0: basic_data_mover</li> <li>dm2pcie_fifo: dc_fifo_wrapper_infill</li> <li> <p>Description  ///////////////// Datamover To PCIe FIFO //////////////////////////////////</p> </li> <li> <p>bp_dm2pcie_fifo: dc_back_pressure</p> </li> <li>dm2pcie_meta_fifo: dc_fifo_wrapper_infill</li> <li>bp_dm2pcie_meta_fifo: dc_back_pressure</li> <li>pcie_tx_pkt_fifo: dc_fifo_wrapper_infill</li> <li>pdu_gen_inst: pdu_gen</li> <li> <p>Description  ///////////////// Datamover To PDU_GEN //////////////////////////////////</p> </li> <li> <p>eth_out_pkt_fifo: dc_fifo_wrapper_infill</p> </li> <li> <p>Description  ///////////////// To OUTPUT FIFO //////////////////////////////////</p> </li> <li> <p>dc_bp_output_pkt_fifo: dc_back_pressure</p> </li> <li>pktbuf_emptylist: dc_fifo_wrapper</li> <li> <p>Description  ///////////////// PKT BUFFER and its Emptylist //////////////////////////////</p> </li> <li> <p>pcie: pcie_top</p> </li> <li>Description  ///////////////PCIe logic ////////////////</li> </ul>"},{"location":"hardware/modules/pcie/bram_mux/","title":"Entity: bram_mux","text":"<ul> <li>File: bram_mux.sv</li> </ul>"},{"location":"hardware/modules/pcie/bram_mux/#diagram","title":"Diagram","text":""},{"location":"hardware/modules/pcie/bram_mux/#description","title":"Description","text":"<p>Use to join multiple BRAM blocks into one (adds 1 cycle delay for write and  2 cycles for read)</p>"},{"location":"hardware/modules/pcie/bram_mux/#generics","title":"Generics","text":"Generic name Type Value Description NB_BRAMS undefined ## Ports Port name Direction Type Description clk input in input out input"},{"location":"hardware/modules/pcie/cpu_to_fpga/","title":"Entity: cpu_to_fpga","text":"<ul> <li>File: cpu_to_fpga.sv</li> </ul>"},{"location":"hardware/modules/pcie/cpu_to_fpga/#diagram","title":"Diagram","text":""},{"location":"hardware/modules/pcie/cpu_to_fpga/#description","title":"Description","text":"<p>This module implements the communication from the CPU to the FPGA (TX). It  is also responsible for managing the TX descriptor queue BRAMs. It outputs  both packets and configuration requests.</p>"},{"location":"hardware/modules/pcie/cpu_to_fpga/#generics","title":"Generics","text":"Generic name Type Value Description NB_QUEUES undefined QUEUE_ID_WIDTH $clog2(NB_QUEUES) ## Ports Port name Direction Type Description clk input rst input out_pkt_sop output Packet buffer output. out_pkt_eop output out_pkt_valid output out_pkt_data output [511:0] out_pkt_empty output [5:0] out_pkt_ready input out_pkt_occup input [31:0] tx_compl_buf_data output TX completion buffer output. tx_compl_buf_valid output tx_compl_buf_ready input tx_compl_buf_occup input [31:0] out_config_data output Config buffer output. out_config_valid output out_config_ready input pcie_rddm_desc_ready input PCIe Read Data Mover (RDDM) signals. pcie_rddm_desc_valid output pcie_rddm_desc_data output [173:0] pcie_rddm_prio_ready input pcie_rddm_prio_valid output pcie_rddm_prio_data output [173:0] pcie_rddm_tx_valid input pcie_rddm_tx_data input [31:0] pcie_rddm_address input [63:0] pcie_rddm_write input pcie_rddm_writedata input [511:0] pcie_rddm_byteenable input [63:0] pcie_rddm_waitrequest output q_table_tails output BRAM signals for TX descriptor queues. q_table_heads output q_table_l_addrs output q_table_h_addrs output rb_size input [RB_AWIDTH:0] Configure ring buffer size. inflight_desc_limit input [30:0] Configure maximum number of in-flight descriptors. queue_full_signals output [31:0] Counters. dsc_cnt output [31:0] empty_tail_cnt output [31:0] dsc_read_cnt output [31:0] pkt_read_cnt output [31:0] batch_cnt output [31:0] max_inflight_dscs output [31:0] max_nb_req_dscs output [31:0] ## Instantiations <ul> <li>q_table_a_tails: bram_interface_io</li> <li>q_table_a_heads: bram_interface_io</li> <li>q_table_a_l_addrs: bram_interface_io</li> <li>q_table_a_h_addrs: bram_interface_io</li> <li>q_table_b_l_addrs: bram_interface_io</li> <li>q_table_b_h_addrs: bram_interface_io</li> <li>dsc_q_status: bram_simple2port</li> <li>dsc_queue_request_fifo: fifo_wrapper_infill_mlab</li> </ul>"},{"location":"hardware/modules/pcie/cpu_to_fpga/#state-machines","title":"State machines","text":""},{"location":"hardware/modules/pcie/fpga_to_cpu/","title":"Entity: fpga_to_cpu","text":"<ul> <li>File: fpga_to_cpu.sv</li> </ul>"},{"location":"hardware/modules/pcie/fpga_to_cpu/#diagram","title":"Diagram","text":""},{"location":"hardware/modules/pcie/fpga_to_cpu/#description","title":"Description","text":""},{"location":"hardware/modules/pcie/fpga_to_cpu/#ports","title":"Ports","text":"Port name Direction Type Description clk input rst input pkt_buf_in_data input pkt_buf_in_valid input pkt_buf_in_ready output pkt_buf_occup output [F2C_RB_AWIDTH:0] pkt_meta_with_queues_t input metadata_buf_in_valid input metadata_buf_in_ready output metadata_buf_occup output [F2C_RB_AWIDTH:0] tx_compl_buf_in_data input tx_compl_buf_in_valid input tx_compl_buf_in_ready output tx_compl_buf_occup output [31:0] pkt_rb_size input [RB_AWIDTH:0] dsc_rb_size input [RB_AWIDTH:0] pcie_bas_waitrequest input pcie_bas_address output [63:0] pcie_bas_byteenable output [63:0] pcie_bas_read output pcie_bas_readdata input [511:0] pcie_bas_readdatavalid input pcie_bas_write output pcie_bas_writedata output [511:0] pcie_bas_burstcount output [3:0] pcie_bas_response input [1:0] pcie_core_full_cnt output [31:0] dma_dsc_cnt output [31:0] dma_dsc_drop_cnt output [31:0] dma_pkt_flit_cnt output [31:0] dma_pkt_flit_drop_cnt output [31:0] ## State machines"},{"location":"hardware/modules/pcie/jtag_mmio_arbiter/","title":"Entity: jtag_mmio_arbiter","text":"<ul> <li>File: jtag_mmio_arbiter.sv</li> </ul>"},{"location":"hardware/modules/pcie/jtag_mmio_arbiter/#diagram","title":"Diagram","text":""},{"location":"hardware/modules/pcie/jtag_mmio_arbiter/#description","title":"Description","text":""},{"location":"hardware/modules/pcie/jtag_mmio_arbiter/#generics","title":"Generics","text":"Generic name Type Value Description PKT_QUEUE_RD_DELAY 2 ## Ports Port name Direction Type Description pcie_clk input jtag_clk input pcie_reset_n input pcie_address_0 input [PCIE_ADDR_WIDTH-1:0] pcie_write_0 input pcie_read_0 input pcie_readdatavalid_0 output pcie_readdata_0 output [511:0] pcie_writedata_0 input [511:0] pcie_byteenable_0 input [63:0] status_addr input [29:0] status_read input status_write input status_writedata input [31:0] status_readdata output [31:0] status_readdata_valid output rx_dsc_q_table_tails output rx_dsc_q_table_heads output rx_dsc_q_table_l_addrs output rx_dsc_q_table_h_addrs output tx_dsc_q_table_tails output tx_dsc_q_table_heads output tx_dsc_q_table_l_addrs output tx_dsc_q_table_h_addrs output pkt_q_table_tails output pkt_q_table_heads output pkt_q_table_l_addrs output pkt_q_table_h_addrs output control_regs output [31:0] ## Instantiations <ul> <li>jtag_to_pcie_fifo: dc_fifo_reg_core</li> <li>jtag_to_pcie_wr_data_fifo: dc_fifo_reg_core</li> <li>pcie_to_jtag_fifo: dc_fifo_reg_core</li> </ul>"},{"location":"hardware/modules/pcie/pcie_core/","title":"Entity: pcie_core","text":"<ul> <li>File: pcie_core.sv</li> </ul>"},{"location":"hardware/modules/pcie/pcie_core/#diagram","title":"Diagram","text":""},{"location":"hardware/modules/pcie/pcie_core/#ports","title":"Ports","text":"Port name Direction Type Description refclk_clk input wire pcie_rstn_npor input wire pcie_rstn_pin_perst input wire wrdm_desc_ready output wire wrdm_desc_valid input wire wrdm_desc_data input wire [173:0] wrdm_prio_ready output wire wrdm_prio_valid input wire wrdm_prio_data input wire [173:0] wrdm_tx_valid output wire wrdm_tx_data output wire [31:0] rddm_desc_ready output wire rddm_desc_valid input wire rddm_desc_data input wire [173:0] rddm_prio_ready output wire rddm_prio_valid input wire rddm_prio_data input wire [173:0] rddm_tx_valid output wire rddm_tx_data output wire [31:0] bas_waitrequest output wire bas_address input wire [63:0] bas_byteenable input wire [63:0] bas_read input wire bas_readdata output wire [511:0] bas_readdatavalid output wire bas_write input wire bas_writedata input wire [511:0] bas_burstcount input wire [3:0] bas_response output wire [1:0] xcvr_rx_in0 input wire xcvr_rx_in1 input wire xcvr_rx_in2 input wire xcvr_rx_in3 input wire xcvr_rx_in4 input wire xcvr_rx_in5 input wire xcvr_rx_in6 input wire xcvr_rx_in7 input wire xcvr_rx_in8 input wire xcvr_rx_in9 input wire xcvr_rx_in10 input wire xcvr_rx_in11 input wire xcvr_rx_in12 input wire xcvr_rx_in13 input wire xcvr_rx_in14 input wire xcvr_rx_in15 input wire xcvr_tx_out0 output wire xcvr_tx_out1 output wire xcvr_tx_out2 output wire xcvr_tx_out3 output wire xcvr_tx_out4 output wire xcvr_tx_out5 output wire xcvr_tx_out6 output wire xcvr_tx_out7 output wire xcvr_tx_out8 output wire xcvr_tx_out9 output wire xcvr_tx_out10 output wire xcvr_tx_out11 output wire xcvr_tx_out12 output wire xcvr_tx_out13 output wire xcvr_tx_out14 output wire xcvr_tx_out15 output wire pcie_clk output pcie_reset_n output readdata_0 input [511:0] readdatavalid_0 input writedata_0 output [511:0] address_0 output [PCIE_ADDR_WIDTH-1:0] write_0 output read_0 output byteenable_0 output [63:0] rddm_writedata output [511:0] rddm_address output [63:0] rddm_write output rddm_byteenable output [63:0] rddm_waitrequest input ## Instantiations <ul> <li>pcie: pcie_ed</li> </ul>"},{"location":"hardware/modules/pcie/pcie_top/","title":"Entity: pcie_top","text":"<ul> <li>File: pcie_top.sv</li> </ul>"},{"location":"hardware/modules/pcie/pcie_top/#diagram","title":"Diagram","text":""},{"location":"hardware/modules/pcie/pcie_top/#ports","title":"Ports","text":"Port name Direction Type Description pcie_clk input pcie_reset_n input pcie_wrdm_desc_ready input pcie_wrdm_desc_valid output pcie_wrdm_desc_data output [173:0] pcie_wrdm_prio_ready input pcie_wrdm_prio_valid output pcie_wrdm_prio_data output [173:0] pcie_wrdm_tx_valid input pcie_wrdm_tx_data input [31:0] pcie_rddm_desc_ready input pcie_rddm_desc_valid output pcie_rddm_desc_data output [173:0] pcie_rddm_prio_ready input pcie_rddm_prio_valid output pcie_rddm_prio_data output [173:0] pcie_rddm_tx_valid input pcie_rddm_tx_data input [31:0] pcie_bas_waitrequest input pcie_bas_address output [63:0] pcie_bas_byteenable output [63:0] pcie_bas_read output pcie_bas_readdata input [511:0] pcie_bas_readdatavalid input pcie_bas_write output pcie_bas_writedata output [511:0] pcie_bas_burstcount output [3:0] pcie_bas_response input [1:0] pcie_address_0 input [PCIE_ADDR_WIDTH-1:0] pcie_write_0 input pcie_read_0 input pcie_readdatavalid_0 output pcie_readdata_0 output [511:0] pcie_writedata_0 input [511:0] pcie_byteenable_0 input [63:0] pcie_rddm_address input [63:0] pcie_rddm_write input pcie_rddm_writedata input [511:0] pcie_rddm_byteenable input [63:0] pcie_rddm_waitrequest output pcie_rx_pkt_buf_data input pcie_rx_pkt_buf_valid input pcie_rx_pkt_buf_ready output pcie_rx_pkt_buf_occup output [F2C_RB_AWIDTH:0] pcie_rx_meta_buf_data input pcie_rx_meta_buf_valid input pcie_rx_meta_buf_ready output pcie_rx_meta_buf_occup output [F2C_RB_AWIDTH:0] pcie_tx_pkt_sop output pcie_tx_pkt_eop output pcie_tx_pkt_valid output pcie_tx_pkt_data output [511:0] pcie_tx_pkt_empty output [5:0] pcie_tx_pkt_ready input pcie_tx_pkt_occup input [31:0] out_config_data output out_config_valid output out_config_ready input disable_pcie output sw_reset output eth_port_nb output pcie_core_full_cnt output [31:0] rx_dma_dsc_cnt output [31:0] rx_dma_dsc_drop_cnt output [31:0] rx_dma_pkt_flit_cnt output [31:0] rx_dma_pkt_flit_drop_cnt output [31:0] cpu_dsc_buf_full_cnt output [31:0] cpu_dsc_buf_in_cnt output [31:0] cpu_dsc_buf_out_cnt output [31:0] cpu_pkt_buf_full_cnt output [31:0] cpu_pkt_buf_in_cnt output [31:0] cpu_pkt_buf_out_cnt output [31:0] st_ord_in_cnt output [31:0] st_ord_out_cnt output [31:0] rx_ignored_head_cnt output [31:0] tx_q_full_signals output [31:0] tx_dsc_cnt output [31:0] tx_empty_tail_cnt output [31:0] tx_dsc_read_cnt output [31:0] tx_pkt_read_cnt output [31:0] tx_batch_cnt output [31:0] tx_max_inflight_dscs output [31:0] tx_max_nb_req_dscs output [31:0] tx_dma_pkt_cnt output [31:0] rx_pkt_head_upd_cnt output [31:0] tx_dsc_tail_upd_cnt output [31:0] top_full_signals_1 output [31:0] top_full_signals_2 output [31:0] clk_status input status_addr input [29:0] status_read input status_write input status_writedata input [31:0] status_readdata output [31:0] status_readdata_valid output ## Instantiations <ul> <li>head_upd_queue: fifo_wrapper_infill_mlab</li> <li>rx_dsc_q_table_tails: bram_interface_io</li> <li>rx_dsc_q_table_heads: bram_interface_io</li> <li>rx_dsc_q_table_l_addrs: bram_interface_io</li> <li>rx_dsc_q_table_h_addrs: bram_interface_io</li> <li>tx_dsc_q_table_tails: bram_interface_io</li> <li>tx_dsc_q_table_heads: bram_interface_io</li> <li>tx_dsc_q_table_l_addrs: bram_interface_io</li> <li>tx_dsc_q_table_h_addrs: bram_interface_io</li> <li>pkt_q_table_tails: bram_interface_io</li> <li>pkt_q_table_heads: bram_interface_io</li> <li>pkt_q_table_l_addrs: bram_interface_io</li> <li>pkt_q_table_h_addrs: bram_interface_io</li> <li>pqm_pkt_q_table_tails[NB_PKT_QUEUE_MANAGERS]: bram_interface_io</li> <li>pqm_pkt_q_table_heads[NB_PKT_QUEUE_MANAGERS]: bram_interface_io</li> <li>pqm_pkt_q_table_l_addrs[NB_PKT_QUEUE_MANAGERS]: bram_interface_io</li> <li>pqm_pkt_q_table_h_addrs[NB_PKT_QUEUE_MANAGERS]: bram_interface_io</li> <li>pkt_q_table_tails_mux: bram_mux</li> <li>pkt_q_table_heads_mux: bram_mux</li> <li>pkt_q_table_l_addrs_mux: bram_mux</li> <li>pkt_q_table_h_addrs_mux: bram_mux</li> <li>jtag_mmio_arbiter_inst: jtag_mmio_arbiter</li> <li>pkt_queue_manager_inst [NB_PKT_QUEUE_MANAGERS]: pkt_queue_manager</li> <li>rx_dsc_queue_manager_inst: rx_dsc_queue_manager</li> <li>fpga_to_cpu_inst: fpga_to_cpu</li> <li>cpu_to_fpga_inst: cpu_to_fpga</li> </ul>"},{"location":"hardware/modules/pcie/queue_manager/","title":"Entity: queue_manager","text":"<ul> <li>File: queue_manager.sv</li> </ul>"},{"location":"hardware/modules/pcie/queue_manager/#diagram","title":"Diagram","text":""},{"location":"hardware/modules/pcie/queue_manager/#description","title":"Description","text":"<p>This module manages generic queues. It fetches the appropriate packet queue  state and adds it to the packet's metadata. It also advances the queue's  pointer. This means that packets cannot be dropped after they go through  this module.</p>"},{"location":"hardware/modules/pcie/queue_manager/#generics","title":"Generics","text":"Generic name Type Value Description NB_QUEUES undefined Number of queue in the module. EXTRA_META_BITS undefined Number of bits in the extra metadata. UNIT_POINTER 0 Set to 1 to advance pointer by a single unit. QUEUE_ID_WIDTH $clog2(NB_QUEUES) Queue ID width. IN_FIFO_DEPTH 16 Depth of the input FIFO. OUT_FIFO_DEPTH 16 Depth of the output FIFO. ALMOST_FULL_THRESHOLD undefined Almost full threshold for the output FIFO. ## Ports Port name Direction Type Description clk input rst input in_pass_through input If set, the packet passes through without changing the queue state (i.e., we do not advance the queue pointer). in_queue_id input [QUEUE_ID_WIDTH-1:0] Input metadata stream. in_size input [$clog2(MAX_PKT_SIZE):0] (In number of flits.) in_meta_extra input [EXTRA_META_BITS-1:0] in_meta_valid input in_meta_ready output queue_state_t output Output metadata stream. out_drop output out_meta_extra output [EXTRA_META_BITS-1:0] out_meta_valid output out_meta_ready input q_table_tails input BRAM signals for queues. q_table_heads input q_table_l_addrs input q_table_h_addrs input rb_size input [RB_AWIDTH:0] Config signals. full_cnt output [31:0] Number of packets dropped because the queue was full. in_cnt output [31:0] Number of input packets. out_cnt output [31:0] Number of output packets. ## Instantiations <ul> <li>q_table_a_tails: bram_interface_io</li> <li>q_table_a_heads: bram_interface_io</li> <li>q_table_a_l_addrs: bram_interface_io</li> <li>q_table_a_h_addrs: bram_interface_io</li> </ul>"},{"location":"hardware/modules/pcie/rx_dsc_queue_manager/","title":"Entity: rx_dsc_queue_manager","text":"<ul> <li>File: rx_dsc_queue_manager.sv</li> </ul>"},{"location":"hardware/modules/pcie/rx_dsc_queue_manager/#diagram","title":"Diagram","text":""},{"location":"hardware/modules/pcie/rx_dsc_queue_manager/#description","title":"Description","text":""},{"location":"hardware/modules/pcie/rx_dsc_queue_manager/#generics","title":"Generics","text":"Generic name Type Value Description NB_QUEUES undefined ## Ports Port name Direction Type Description clk input rst input pkt_meta_with_queues_t input in_meta_valid input in_meta_ready output pkt_meta_with_queues_t output out_meta_valid output out_meta_ready input q_table_tails input q_table_heads input q_table_l_addrs input q_table_h_addrs input rb_size input [RB_AWIDTH:0] full_cnt output [31:0] in_cnt output [31:0] out_cnt output [31:0]"},{"location":"primitives/","title":"Primitives","text":""},{"location":"primitives/device/","title":"Device","text":"<p>The <code>Device</code> class is the main entry point for interacting with the hardware device. It is used to allocate Ens\u014d Pipes as well as to configure the device. It can also be used to efficiently receive data from multiple pipes, avoiding the need to probe each pipe individually.</p> <p>Every I/O thread in a program should instantiate its own <code>Device</code> instance using the <code>Device::Create()</code> factory method. <code>Device</code> objects, like pipe objects, are not meant to be thread safe. They are designed to be used by a single thread only.</p>"},{"location":"primitives/device/#allocating-enso-pipes","title":"Allocating Ens\u014d Pipes","text":"<p>After instantiating a device, the application can allocate Ens\u014d Pipes of any of the three types, using the appropriate method:</p> <ul> <li><code>Device::AllocateRxPipe()</code> to allocate an RX Ens\u014d Pipe.</li> <li><code>Device::AllocateTxPipe()</code> to allocate a TX Ens\u014d Pipe.</li> <li><code>Device::AllocateRxTxPipe()</code> to allocate an RX/TX Ens\u014d Pipe.</li> </ul> <p>RX Ens\u014d Pipes and RX/TX Ens\u014d Pipes can also be set as fallback when being allocated. Fallback pipes receive packets that do not match any explicit bind rules. See Binding and flow steering for more details on how the NIC steers packets to fallback pipes.</p> <p>To set a pipe as fallback, both <code>Device::AllocateRxPipe()</code> and <code>Device::AllocateRxTxPipe()</code> accept an optional boolean argument that specifies whether the pipe should be set as fallback. For example:</p> <pre><code>RxPipe* rx_pipe_1 = dev-&gt;AllocateRxPipe();     // Normal pipe, non-fallback.\nRxPipe* rx_pipe_2 = dev-&gt;AllocateRxPipe(true); // Set as fallback.\n</code></pre>"},{"location":"primitives/device/#receiving-data-from-multiple-pipes","title":"Receiving Data from Multiple Pipes","text":"<p>Threads can also use <code>Device</code> instances to figure out which pipe has data pending to be received. This is useful when the application needs to receive data from multiple pipes, as it avoids the need to probe each pipe individually.1</p> <p>To figure out the next pipe with data pending, the application can call <code>Device::NextRxPipeToRecv()</code> or <code>Device::NextRxTxPipeToRecv()</code>. This will return the next pipe with data pending to be received, or <code>nullptr</code> if no pipe has data pending. Here is an example that receives data from multiple pipes:</p> <pre><code>// Allocate device.\nstd::unique_ptr&lt;Device&gt; dev = Device::Create();\n\n// Allocate RX pipes.\nRxPipe* rx_pipe_1 = dev-&gt;AllocateRxPipe();\nRxPipe* rx_pipe_2 = dev-&gt;AllocateRxPipe();\n\nwhile (keep_running) {\n// Figure out the next pipe with data pending to be received.\nRxPipe* pipe = dev-&gt;NextRxPipeToRecv();\n\nif (pipe == nullptr) continue;\n\npipe-&gt;Recv(); // (1)!\n\n// Do something with the received data.\n// [...]\n\npipe-&gt;Clear();\n}\n</code></pre> <ol> <li> Refer to the RX Ens\u014d Pipe documentation for more information on how to receive data from an Ens\u014d Pipe.</li> </ol> <p>Note</p> <p>There is an important caveat to consider when using these methods: they do not work if the application has a mix of RX and RX/TX pipes. If you plan to use those methods, make sure you only use one type of RX pipe.</p>"},{"location":"primitives/device/#configuring-the-device","title":"Configuring the Device","text":"<p>You may also use a <code>Device</code> instance to configure the hardware device.</p>"},{"location":"primitives/device/#hardware-rate-limiter","title":"Hardware Rate Limiter","text":"<p>The hardware implementation includes a rate limiter that can be used to limit the rate at which packets are sent. The rate limiter is applied to all packets sent by the device, regardless of the pipe they are sent on. That means that even if you enable rate limiting from a specific thread, it will affect pipes from all threads. The rate limiter can be enabled by calling <code>Device::EnableRateLimiting()</code> and disabled by calling <code>Device::DisableRateLimiting()</code>.</p> <p>When enabling the rate limiter, you specify a fraction <code>num / den</code> of the maximum hardware flit rate (a flit is 64 bytes). The maximum hardware flit rate is defined by the <code>kMaxHardwareFlitRate</code> constant and is 200MHz by default. This will cause packets from all queues to be sent at a rate of <code>num / den * kMaxHardwareFlitRate</code> flits per second. Note that this is slightly different from how we typically define throughput and you will need to take the packet sizes into account to set this properly.</p> <p>For example, suppose that you are sending 64-byte packets. Each packet occupies exactly one flit. For this packet size, line rate at 100Gbps is 148.8Mpps. So if <code>kMaxHardwareFlitRate</code> is 200MHz, line rate actually corresponds to a 744/1000 rate. Therefore, if you want to send at 50Gbps (50% of line rate), you can use a 372/1000 (or 93/250) rate.</p> <p>The other thing to notice is that, while it might be tempting to use a large denominator in order to increase the rate precision. This has the side effect of increasing burstiness. The way the rate limiter is implemented, we send a burst of <code>num</code> consecutive flits every <code>den</code> cycles. Which means that if <code>num</code> is too large, it might overflow the receiver buffer. For instance, in the example above, 93/250 would be a better rate than 372/1000. And 3/8 would be even better with a slight loss in precision.</p> <p>You can find the maximum packet rate for any packet size by using the expression: <code>line_rate / ((pkt_size + 20) * 8)</code>. So for 100Gbps and 128-byte packets we have: <code>100e9 / ((128 + 20) * 8)</code> packets per second. Given that each packet is two flits, for <code>kMaxHardwareFlitRate = 200e6</code>, the maximum rate is <code>100e9 / ((128 + 20) * 8) * 2 / 200e6</code>, which is approximately 125/148. Therefore, if you want to send packets at 20Gbps (20% of line rate), you should use a 25/148 rate.</p>"},{"location":"primitives/device/#hardware-time-stamping","title":"Hardware Time Stamping","text":"<p>The hardware implementation can also time stamp packets as they are sent and compute the RTT when they return. This is useful to measure latency. As with the rate limiter, this configuration is applied to all pipes. You can enable time stamping by calling <code>Device::EnableTimeStamping()</code> and disable it by calling <code>Device::DisableTimeStamping()</code>.</p> <p>When timestamping is enabled, all outgoing packets will receive a timestamp and all incoming packets will have an RTT (in number of cycles). You may use <code>get_pkt_rtt()</code> to retrieve the RTT for a returning packet. This function will return the RTT in number of cycles. You can convert it to nanoseconds by multiplying it by <code>kNsPerTimestampCycle</code>.</p>"},{"location":"primitives/device/#round-robin-steering","title":"Round-Robin Steering","text":"<p>As described in Binding and flow steering, the NIC sends packets that do not match any binding rules to fallback pipes. By default, this is done using a hash of the five-tuple. You can change it to use round-robin instead by using <code>Device::EnableRoundRobin()</code> or revert back to the default by using <code>Device::DisableRoundRobin()</code>.</p> <ol> <li> <p>This is analogous to the <code>select(2)</code> system call in POSIX.\u00a0\u21a9</p> </li> </ol>"},{"location":"primitives/rx_enso_pipe/","title":"RX Ens\u014d Pipe","text":"<p>RX Ens\u014d Pipes are used to receive data from the NIC. They offer multiple options for receiving data, including byte streams, raw packets, or application-level messages. The appropriate option to use depends on the level of abstraction supported by the NIC and required by the application.</p>"},{"location":"primitives/rx_enso_pipe/#allocating-rx-enso-pipes","title":"Allocating RX Ens\u014d Pipes","text":"<p>You need to use a Device object to allocate an RX Ens\u014d Pipe. For example:</p> <pre><code>RxPipe* rx_pipe = device-&gt;AllocateRxPipe();\nassert(rx_pipe != nullptr);\n</code></pre> <p>Note that pipes are not thread safe. Each thread that receives data in a program should allocate its own device instance and RX Ens\u014d Pipes.</p>"},{"location":"primitives/rx_enso_pipe/#receiving-byte-streams","title":"Receiving byte streams","text":"<p>The most generic way of receiving data in an RX Ens\u014d Pipe is to use <code>RxPipe::Recv()</code>. It will return the next chunk of bytes available in the pipe.</p> <p>After calling <code>RxPipe::Recv()</code>, the application will own the data and is responsible for freeing it once it is done processing. To do so, the application should call <code>RxPipe::Free()</code> or <code>RxPipe::Clear()</code>. The difference between the two is that <code>RxPipe::Free()</code> takes as argument the number of bytes to free, while <code>RxPipe::Clear()</code> frees all the data currently owned by the application. Note that received data can only be freed sequentially.</p> <p>The following example shows how to use <code>RxPipe::Recv()</code> and <code>RxPipe::Clear()</code> to receive, process, and free data.</p> <pre><code>RxPipe* rx_pipe = device-&gt;AllocateRxPipe(); // (1)!\nassert(rx_pipe != nullptr);\n\n// This is arbitrary and can be tuned to the application's needs.\nconstexpr uint32_t kMaxBatchSize = 65536;\n\nuint8_t* buf;\n\nuint32_t nb_bytes_received = rx_pipe-&gt;Recv(&amp;buf, kMaxBatchSize);\n\n// Do something with the received data.\n// [...]\n\n// Freeing all the received data.\nrx_pipe-&gt;Clear();\n</code></pre> <ol> <li> Note that you should use a Device instance to allocate an RX Ens\u014d Pipe.</li> </ol>"},{"location":"primitives/rx_enso_pipe/#accumulating-data","title":"Accumulating data","text":"<p>Applications do not need to process all the data received at once. Instead, they may choose to accumulate data, calling <code>RxPipe::Recv()</code> multiple times before finally freeing it. At any point, the application can check the number of bytes that it currently owns by calling <code>RxPipe::capacity()</code>.</p> <p>While applications are free to accumulate data, they should be careful not to accumulate too much. If the application does not free the data, it will eventually own the entire RX Ens\u014d Pipe's buffer. This will prevent new data from being received from the NIC.</p> <p>Note</p> <p>Applications cannot own more data than the RX Ens\u014d Pipe's overall capacity (<code>RxPipe::kMaxCapacity</code>). As such, if <code>RxPipe::capacity()</code> is equal to <code>RxPipe::kMaxCapacity</code>, calling <code>RxPipe::Recv()</code> will always return 0. As a rule of thumb, try to prevent <code>RxPipe::capacity()</code> from exceeding <code>RxPipe::kMaxCapacity / 2</code>.</p>"},{"location":"primitives/rx_enso_pipe/#peeking","title":"Peeking","text":"<p>Sometimes, it is useful to be able to peek at the data without actually consuming it.1 This can be accomplished by using <code>RxPipe::Peek()</code>. <code>RxPipe::Peek()</code> works similarly to <code>RxPipe::Recv()</code>, except that it does not consume the data from the pipe. As such, a later call to <code>RxPipe::Peek()</code> or <code>RxPipe::Recv()</code> will return the same data. If desired, the application can call <code>RxPipe::ConfirmBytes()</code> to explicitly consume the data after peeking.</p>"},{"location":"primitives/rx_enso_pipe/#receiving-raw-packets","title":"Receiving raw packets","text":"<p>While <code>RxPipe::Recv()</code> can be used to receive generic data, RX Ens\u014d Pipes also support a more convenient way of receiving raw packets. The <code>RxPipe::RecvPkts()</code> method returns a batch of packets that can be iterated over using a range-based for loop. The following example shows how to use <code>RxPipe::RecvPkts()</code> to receive and process packets.</p> <pre><code>auto batch = rx_pipe-&gt;RecvPkts();\nfor (auto pkt : batch) {\n// Do something with the packet.\n// [...]\n}\n\nrx_pipe-&gt;Clear();\n</code></pre> <p>In the example above, there is no limit to the batch of packets returned by <code>RxPipe::RecvPkts()</code>. If desired, you may also set a maximum batch size (in number of packets) when calling <code>RxPipe::RecvPkts()</code>. After iterating over a batch, you can retrieve the total number of bytes in the batch by calling <code>RxPipe::MessageBatch::processed_bytes()</code>. For example:</p> <pre><code>RxPipe* rx_pipe = device-&gt;AllocateRxPipe();\nassert(rx_pipe != nullptr);\n\n// This is arbitrary and can be tuned to the application's needs.\nconstexpr uint32_t kMaxPktBatchSize = 1024;\n\nauto batch = rx_pipe-&gt;RecvPkts(kMaxPktBatchSize);\n\n// Should print \"Processed bytes: 0\".\nstd::cout &lt;&lt; \"Processed bytes: \" &lt;&lt; batch.processed_bytes() &lt;&lt; std::endl;\n\nfor (auto pkt : batch) {\n// Do something with the packet.\n// [...]\n}\n\n// Will show the total number of bytes processed in the batch.\nstd::cout &lt;&lt; \"Processed bytes: \" &lt;&lt; batch.processed_bytes() &lt;&lt; std::endl;\n\nrx_pipe-&gt;Clear();\n</code></pre> <p>In addition to <code>RxPipe::RecvPkts()</code>, RX Ens\u014d Pipes also support peeking packets using <code>RxPipe::PeekPkts()</code>. Similar to <code>RxPipe::Peek()</code>, <code>RxPipe::PeekPkts()</code> does not consume the data from the pipe.</p>"},{"location":"primitives/rx_enso_pipe/#receiving-generic-messages","title":"Receiving generic messages","text":"<p>The third way of receiving data is by using <code>RxPipe::RecvMessages()</code>. <code>RxPipe::RecvMessages()</code> allows the application to use its own message format. In fact, <code>RxPipe::RecvPkts()</code> and <code>RxPipe::PeekPkts()</code> are just special cases of <code>RxPipe::RecvMessages()</code> for raw packets.</p> <p>To use <code>RxPipe::RecvMessages()</code> applications must supply an implementation of a message iterator. To do so, define a class that inherits from <code>MessageIteratorBase</code>. This class should implement two methods: <code>GetNextMessage()</code> and <code>OnAdvanceMessage()</code>:</p> <ul> <li><code>GetNextMessage()</code> takes as argument the current message in the batch. It should use this message to return the address of the next message.</li> <li><code>OnAdvanceMessage()</code> takes as argument the number of bytes from the last message and is called whenever the application has finished processing a message. It can be used, for instance, to call <code>ConfirmBytes()</code> on the pipe.</li> </ul> <p>The following example shows the implementation of the message iterator for raw packets.</p> <pre><code>#include &lt;enso/helpers.h&gt;\n#include &lt;enso/pipe.h&gt;\n\nnamespace enso {\n\nclass PktIterator : public MessageIteratorBase&lt;PktIterator&gt; {\npublic:\ninline PktIterator(uint8_t* addr, int32_t message_limit,\nRxPipe::MessageBatch&lt;PktIterator&gt;* batch)\n: MessageIteratorBase(addr, message_limit, batch) {} // (1)!\n\nconstexpr uint8_t* GetNextMessage(uint8_t* current_message) {\nreturn get_next_pkt(current_message); // (2)!\n}\n\nconstexpr void OnAdvanceMessage(uint32_t nb_bytes) {\nbatch_-&gt;pipe_-&gt;ConfirmBytes(nb_bytes); // (3)!\n}\n};\n\n}  // namespace enso\n</code></pre> <ol> <li>The constructor takes as arguments the address of the first message in the batch, the maximum number of messages to process, and a pointer to the batch. The constructor of the base class must be called with these arguments.</li> <li>We are simply using the <code>get_next_pkt()</code> helper function to get the address of the next packet.</li> <li>You can have access to any member of the batch object. Here, we are calling <code>ConfirmBytes()</code> on the pipe to consume the data. <code>PeekPktIterator</code> simply suppresses this call.</li> </ol> <p>Once you have defined your message iterator, you can then use it to receive messages using <code>RxPipe::RecvMessages()</code> similarly to how you would use <code>RxPipe::RecvPkts()</code>.</p> <pre><code>auto batch = rx_pipe-&gt;RecvMessages&lt;PktIterator&gt;();\n\nfor (auto message : batch) {\n// Do something with the packet.\n// [...]\n}\n\nrx_pipe-&gt;Clear();\n</code></pre>"},{"location":"primitives/rx_enso_pipe/#binding-and-flow-steering","title":"Binding and flow steering","text":"<p>The NIC is responsible for demultiplexing incoming data among the RX Ens\u014d Pipes. The logic to demultiplex packets should depend on the offloads implemented on the NIC. For convenience, our hardware implementation includes three ways of steering incoming data to RX Ens\u014d Pipes: flow binding, hashing, and round robin.</p> <p>Flow binding is implemented using a cuckoo hash table on the NIC. This allows the application to map specific flows to RX Ens\u014d Pipes. We borrow from the socket API terminology and call this mapping between RX Ens\u014d Pipes and flows binding. To bind an RX Ens\u014d Pipe to a flow, you can use <code>RxPipe::Bind()</code>, specifying the flow's five-tuple. You can call <code>RxPipe::Bind()</code> multiple times on the same pipe to bind it to multiple flows.</p> <p>Packets that do not match any flow in the flow table are directed to what we call fallback queues. When you allocate an RX Ens\u014d Pipe, you can set it as fallback (see Allocating Ens\u014d Pipes). If no fallback pipe is currently allocated, packets that do not match any flow are dropped.</p> <p>When multiple fallback pipes are allocated, the NIC can steer packets among them in two different ways. By default, the NIC uses a hash of the packet's 5-tuple to decide which pipe to send the packet. Alternatively, the NIC can also be configured to use round robin (see Round-Robin Steering).</p>"},{"location":"primitives/rx_enso_pipe/#notification-prefetching","title":"Notification Prefetching","text":"<p>Under the hood, Ens\u014d uses a reactive notification mechanism that dramatically improves throughput but that may also increase latency when used by itself. To reduce latency when receiving packets, Ens\u014d also employs a mechanism called notification prefetching, that causes software to preemptively request new notifications from the NIC. Ens\u014d supports two types of notification prefetching: implicit and explicit.</p> <p>By default, Ens\u014d already prefetches notifications implicitly. Applications that do not benefit from low latency may choose to disable notification prefetching by compiling Ens\u014d with <code>-Dlatency_opt=false</code>. This will cause the library to only prefetch notifications when explicitly requested by the application. Refer to the build instructions for more details on how to change compile-time options.</p> <p>Alternatively, users that want more control over when notification prefetching happens may choose to prefetch notifications explicitly. To explicitly prefetch notifications for a given pipe, an application can use the <code>RxPipe::Prefetch()</code> method. This will force the NIC to notify any pending data for such pipe.</p>"},{"location":"primitives/rx_enso_pipe/#examples","title":"Examples","text":"<p>The following examples use RX Ens\u014d Pipes:</p> <ul> <li><code>capture.cpp</code></li> <li><code>echo_copy.cpp</code></li> </ul>"},{"location":"primitives/rx_enso_pipe/#summary","title":"Summary","text":"<ul> <li>Use <code>RxPipe::Recv()</code> to receive arbitrary data from an RX Ens\u014d Pipe and <code>RxPipe::Peek()</code> to peek at the data without consuming it.</li> <li>Use <code>RxPipe::RecvPkts()</code> to receive raw packets from an RX Ens\u014d Pipe and <code>RxPipe::PeekPkts()</code> to peek at the packets without consuming them.</li> <li>Use <code>RxPipe::RecvMessages()</code> to receive messages from an RX Ens\u014d Pipe. You must provide a message iterator to use this method.</li> <li>Use <code>RxPipe::Clear()</code> or <code>RxPipe::Free()</code> to free data after you are done processing it.</li> <li>The number of bytes currently owned by the application can be obtained using <code>RxPipe::capacity()</code>.</li> <li>Use <code>RxPipe::Bind()</code> to bind an RX Ens\u014d Pipe to a flow.</li> </ul> <ol> <li> <p>This is analogous to the <code>MSG_PEEK</code> flag in the <code>recv(2)</code> system call.\u00a0\u21a9</p> </li> </ol>"},{"location":"primitives/rx_tx_enso_pipe/","title":"RX/TX Ens\u014d Pipe","text":"<p>RX/TX Ens\u014d Pipes are designed for applications that modify received data in place and then send it back to the NIC without the need to impose copy overhead. They can be seen as a combination of an RX and TX Ens\u014d Pipes, containing a subset of their functionality.</p> <p>RX/TX Ens\u014d Pipes can receive data from the NIC in the same way as RX Ens\u014d Pipes. Therefore, applications can use analogous functions to receive data. Refer to the RX Ens\u014d Pipe documentation for more information about each of those functions:</p> <ul> <li>Receiving byte streams: <code>RxTxPipe::Recv()</code>, <code>RxTxPipe::Peek()</code></li> <li>Receiving raw packets:  <code>RxTxPipe::RecvPkts()</code>, <code>RxTxPipe::PeekPkts()</code></li> <li>Receiving generic messages: <code>RxTxPipe::RecvMessages()</code></li> </ul> <p>Different from RX Ens\u014d Pipes, however, RX/TX Ens\u014d Pipes do not support freeing the data received from the NIC. Instead, all received data is automatically freed after transmission.</p> <p>To send data back to the NIC, applications should call <code>RxTxPipe::SendAndFree()</code>. Note that only data that was previously received can be sent back to the NIC, RX/TX Ens\u014d Pipes do not support extending the buffer as in a TX Ens\u014d Pipe.</p> <p>The following example shows how to use RX/TX Ens\u014d Pipes to echo received packets back to the NIC after incrementing their payload:</p> <pre><code>RxTxPipe* pipe = dev-&gt;AllocateRxTxPipe(); // (1)!\nassert(pipe != nullptr);\n\nwhile (keep_running) {\nauto batch = pipe-&gt;RecvPkts();\nif (unlikely(batch.available_bytes() == 0)) {\ncontinue;\n}\nfor (auto pkt : batch) {\n++pkt[59];  // Increment payload.\n}\npipe-&gt;SendAndFree(batch.processed_bytes());\n}\n</code></pre> <ol> <li> Note that you should use a Device instance to allocate an RX/TX Ens\u014d Pipe.</li> </ol> <p>In this example we poll the RX/TX Ens\u014d Pipe for new packets. If there are no packets available, we skip the current iteration of the loop. Otherwise, we increment the payload of each packet and send them back to the NIC.</p>"},{"location":"primitives/rx_tx_enso_pipe/#examples","title":"Examples","text":"<p>The following examples use RX/TX Ens\u014d Pipes:</p> <ul> <li><code>echo.cpp</code></li> <li><code>echo_event.cpp</code></li> </ul>"},{"location":"primitives/tx_enso_pipe/","title":"TX Ens\u014d Pipe","text":"<p>TX Ens\u014d Pipes work in reverse to RX Ens\u014d Pipes and are used to transmit data to the NIC. To send data through a TX Ens\u014d Pipe, the application allocates a buffer within the pipe, fill it with data and then send it.</p>"},{"location":"primitives/tx_enso_pipe/#allocating-a-tx-enso-pipe","title":"Allocating a TX Ens\u014d Pipe","text":"<p>You need to use a Device object to allocate a TX Ens\u014d Pipe. For example:</p> <pre><code>enso::TxPipe* tx_pipe = device-&gt;AllocateTxPipe();\nassert(tx_pipe != nullptr);\n</code></pre> <p>Note that pipes are not thread safe. Each thread that receives data in a program should allocate its own device instance and TX Ens\u014d Pipes.</p>"},{"location":"primitives/tx_enso_pipe/#allocating-a-buffer","title":"Allocating a buffer","text":"<p>TX Ens\u014d Pipes manage memory through a simple best-effort allocator. The allocator will always try to return the largest contiguous buffer possible within a given TX Ens\u014d Pipe. The allocated buffer's capacity can also implicitly increase at any point but it will never implicitly decrease.</p> <p>To request a buffer, the application calls <code>TxPipe::AllocateBuf()</code> with a target size. This will return a buffer with size at least as large as the target. Each pipe can only allocate a single buffer at a time. If the application calls <code>TxPipe::AllocateBuf()</code> while a buffer is still valid, the function will return the same buffer. Since the buffer's capacity can implicitly increase, the application can always retrieve the current capacity by calling <code>TxPipe::capacity()</code>.</p> <p>Note</p> <p>The application should never call <code>TxPipe::AllocateBuf()</code> with a target larger than the TX Ens\u014d Pipe's overall capacity (<code>TxPipe::kMaxCapacity</code>). Doing so would cause the function to block indefinitely.</p>"},{"location":"primitives/tx_enso_pipe/#transmitting-data","title":"Transmitting data","text":"<p>Once ready to send data, the application calls <code>TxPipe::SendAndFree()</code>, specifying the amount of data to be sent. This will send the data and free the buffer.</p> <p>Here is an example of how to use a <code>TxPipe</code>:</p> <pre><code>enso::TxPipe* tx_pipe = device-&gt;AllocateTxPipe(); // (1)!\nassert(tx_pipe != nullptr);\n\n// Allocate a buffer.\nuint8_t* buf = tx_pipe-&gt;AllocateBuf(data_size);\n\n// Fill the buffer with data.\n// [...]\n\n// Send the data.\ntx_pipe-&gt;SendAndFree(data_size);\n\n// The previous buffer is now invalid, allocate a new one.\nbuf = tx_pipe.AllocateBuf(data_size2);\n</code></pre> <ol> <li> Note that you should use a Device instance to allocate a TX Ens\u014d Pipe.</li> </ol> <p>In the previous example, we knew the amount of data to be transmitted and we explicitly specified it as the target when calling <code>TxPipe::AllocateBuf()</code>. This works well for smaller transfers or when we know the pipe's capacity is large enough to hold the data. However, if the target is too large, it will cause <code>TxPipe::AllocateBuf()</code> to block waiting for enough free space in the TX Ens\u014d Pipe. To avoid this, one may use the TxPipe in a different way. Instead of explicitly setting a target size when allocating the buffer, we can let the pipe dictate how much data that can be sent at a given time. For example:</p> <pre><code>enso::TxPipe* tx_pipe = device-&gt;AllocateTxPipe();\nassert(tx_pipe != nullptr);\n\n// Allocate a buffer. Note that we do not specify a target size.\n// This makes sure that AllocateBuf will never block.\nuint8_t* buf = tx_pipe-&gt;AllocateBuf();\n\n// Retrieve the buffer's current capacity.\nuint32_t data_size = tx_pipe-&gt;capacity();\n\n// Fill the buffer with data, up to the buffer's capacity.\n// [...]\n\n// Send the data.\ntx_pipe-&gt;SendAndFree(data_size);\n\n// The previous buffer is now invalid, allocate a new one.\nbuf = tx_pipe.AllocateBuf();\n</code></pre>"},{"location":"primitives/tx_enso_pipe/#partial-transfers","title":"Partial transfers","text":"<p>So far we have always transmitted the entire allocated buffer. However, sometimes it is useful to send only a portion of the buffer. This can be easily achieved by calling <code>TxPipe::SendAndFree()</code> with a size smaller than the buffer's capacity. The function will send the specified amount of data, starting from the beginning of the buffer, ignoring all data after the specified size.</p> <p>Things get more interesting when the part of the buffer that was not sent needs to be used in a subsequent transfer. For instance, the buffer may contain an incomplete message that should be completed before it is sent in the next transfer. In this case, the application can rely on the fact that the data that was not sent will be available in the next buffer allocated using <code>TxPipe::AllocateBuf()</code>.</p> <p>The following diagram illustrates this behavior. At step \u2460, the application allocates Buffer 1 using <code>TxPipe::AllocateBuf()</code>. At step \u2461, the application partially fills the buffer with data but sends only a portion of it using <code>TxPipe::SendAndFree()</code>. At step \u2462, the application allocates Buffer 2 using <code>TxPipe::AllocateBuf()</code>. The new buffer starts with the unsent data from the previous buffer.</p> <p> </p> Example of a partial transfer. The unsent data is available in the next buffer returned by TxPipe::AllocateBuf()."},{"location":"primitives/tx_enso_pipe/#extending-a-buffer","title":"Extending a buffer","text":"<p>Since the buffer size can implicitly increase at any point, the application can fetch the current buffer's capacity by calling <code>TxPipe::capacity()</code>. The application can also explicitly request a buffer extension by calling <code>TxPipe::TryExtendBuf()</code> or <code>TxPipe::ExtendBufToTarget()</code>. When calling <code>TxPipe::TryExtendBuf()</code>, the TX Ens\u014d Pipe allocator will check for completions to try to extend the allocated buffer's capacity but it will not block. When calling <code>TxPipe::ExtendBufToTarget()</code>, the TX Ens\u014d Pipe allocator will block until the requested capacity is available.</p> <p>Note that the previous buffer is not invalidated after calling <code>TxPipe::TryExtendBuf()</code> or <code>TxPipe::ExtendBufToTarget()</code>. Buffers only become invalid after calling <code>TxPipe::SendAndFree()</code>.</p>"},{"location":"primitives/tx_enso_pipe/#examples","title":"Examples","text":"<p>The following examples use TX Ens\u014d Pipes:</p> <ul> <li><code>echo_copy.cpp</code></li> </ul>"},{"location":"primitives/tx_enso_pipe/#summary","title":"Summary","text":"<ul> <li><code>TxPipe::AllocateBuf()</code> will return the maximum contiguous buffer possible for a given TX Ens\u014d Pipe.</li> <li>Applications can use <code>TxPipe::AllocateBuf()</code> to allocate a buffer of a minimum target size or they can use <code>TxPipe::AllocateBuf(0)</code> to avoid blocking.</li> <li>The allocated buffer's capacity can be retrieved by calling <code>TxPipe::capacity()</code>.</li> <li>The allocated buffer's capacity can implicitly increase at any point but it will never implicitly decrease.</li> <li>If needed, the application can request a buffer extension by calling <code>TxPipe::TryExtendBuf()</code> or <code>TxPipe::ExtendBufToTarget()</code>.</li> <li>The buffer returned by <code>TxPipe::AllocateBuf()</code> is valid until we call <code>TxPipe::SendAndFree()</code>. Even explicit extensions do not invalidate the buffer.</li> <li>After calling <code>TxPipe::SendAndFree()</code>, the application should call <code>TxPipe::AllocateBuf()</code> again to get a new buffer.</li> <li>If the buffer was only partially sent, the new allocated buffer will start with the remaining data.</li> <li>The application should not try to modify data from a sent buffer, doing so will result in undefined behavior.</li> </ul>"}]}